---
layout: post  
title: "XJTU-AUTO300527 notes"  
date: 2024-05-29 00:10 +0800  
last_modified_at: 2024-06-02 14:00 +0800  
tags: [Course Note]  
math: true  r
toc: true  
excerpt: "æœºå™¨å­¦ä¹ è¯¾ç¨‹ä¸€äº›ç–‘éš¾ç‚¹çš„è§£å†³ï¼ˆTBCï¼‰"
---

# æ±‚è§£çº¿æ€§å›å½’æ¨¡å‹ï¼ˆp173-178ï¼‰
è®­ç»ƒæ•°æ®ä¸ºğ‘ä¸ªè¾“å…¥æ•°æ®
$$\mathbf{X} =\begin{pmatrix}\mathbf{x_1},\mathbf{x_2},\cdots\mathbf{x_N}
\end{pmatrix}$$
åŠå¯¹åº”å‡½æ•°å€¼
$$\mathbf{t} =\begin{pmatrix}{t_1},{t_2},\cdots{t_N}
\end{pmatrix}$$
æ¨¡å‹ä¸ºçº¿æ€§å›å½’æ¨¡å‹ 
$$y(\mathbf{x},\mathbf{w}) =\mathbf{w}^T\mathbf{\phi(x)}$$

$$
  \mathbf{t} =\begin{pmatrix}
  t_{0}\\
  t_{1} \\
  \vdots \\  
  t_{N}  \\
  \end{pmatrix}_{N \times 1}
$$

$$
  \mathbf{w} =\begin{pmatrix}
  w_{0}\\
  w_{1} \\
  \vdots \\  
  w_{M-1}  \\
  \end{pmatrix}_{(M-1) \times 1}
$$


$$
  \mathbf{\phi}=
  \begin{pmatrix}
  \phi^T(x_1)\\
  \phi^T(x_2)\\
  \vdots \\  
  \phi^T(x_N)\\
  
  \end{pmatrix}=
  \begin{pmatrix}
  \phi_{0}(x_1) & \phi_{1}(x_1) & \phi_{2}(x_1) & \cdots & \phi_{M-1}(x_1)\\
  \phi_{0}(x_2) & \phi_{1}(x_2) & \phi_{2}(x_2) & \cdots & \phi_{M-1}(x_2)\\
  \vdots & \vdots & \ddots & \vdots \\  
  \phi_{0}(x_N) & \phi_{1}(x_N) & \phi_{2}(x_N) & \cdots & \phi_{M-1}(x_N)\\
  \end{pmatrix}_{N\times M}
$$

å› æ­¤å¹³æ–¹å’Œè¯¯å·®å‡½æ•°

$$
 E_D(\mathbf{w})=\frac{1}{2}  \sum_{n=1}^N (t_n-\mathbf{w}^T \mathbf{\phi}(\mathbf{x}_n))^2 $$

 æ±‚å¯¼å¾—

 $$\nabla E_D(\mathbf{w})=\sum_{n=1}^N (t_n-\mathbf{w}^T \mathbf{\phi}(\mathbf{x}_n))\mathbf{\phi}(\mathbf{x}_n)^T 
$$

åˆå¹¶å¯å¾—

$$
\nabla E_D(\mathbf{w}) = \left(
\begin{pmatrix}
t_{0} &t_{1}&\cdots &t_{N}
\end{pmatrix} - \begin{pmatrix}
w_{0} &  w_{1}& \cdots & w_{M-1}
\end{pmatrix} \begin{pmatrix}
\phi(x_1) &  \phi(x_2)& \cdots & \phi(x_N)
\end{pmatrix}\right)

\begin{pmatrix}
\phi^T(x_1)\\
\phi^T(x_2)\\
\vdots \\  
\phi^T(x_N)\\

\end{pmatrix}
$$

å³

$$\nabla E_D(\mathbf{w})= \left(\begin{pmatrix}
t_{0}\\
t_{1} \\
\vdots \\  
t_{N}  \\
\end{pmatrix}^T - \begin{pmatrix}
w_{0}\\
w_{1} \\
\vdots \\  
w_{M-1}  \\
\end{pmatrix}^T \begin{pmatrix}
\phi_{0}(x_1) & \phi_{1}(x_1) & \phi_{2}(x_1) & \cdots & \phi_{M-1}(x_1)\\
\phi_{0}(x_2) & \phi_{1}(x_2) & \phi_{2}(x_2) & \cdots & \phi_{M-1}(x_2)\\
\vdots & \vdots & \ddots & \vdots \\  
\phi_{0}(x_N) & \phi_{1}(x_N) & \phi_{2}(x_N) & \cdots & \phi_{M-1}(x_N)\\
\end{pmatrix}^T\right)\begin{pmatrix}
\phi_{0}(x_1) & \phi_{1}(x_1) & \phi_{2}(x_1) & \cdots & \phi_{M-1}(x_1)\\
\phi_{0}(x_2) & \phi_{1}(x_2) & \phi_{2}(x_2) & \cdots & \phi_{M-1}(x_2)\\
\vdots & \vdots & \ddots & \vdots \\  
\phi_{0}(x_N) & \phi_{1}(x_N) & \phi_{2}(x_N) & \cdots & \phi_{M-1}(x_N)\\
\end{pmatrix}
$$

å³

$$
\nabla E_D(\mathbf{w})=(\mathbf{t}^T-\mathbf{w}^T\mathbf{\Phi}^T)\mathbf{\Phi}
$$

ä»¤å…¶ä¸º0å¯å¾—

$$
\mathbf{t}^T\mathbf{\Phi}=\mathbf{w}^T\mathbf{\Phi}^T\mathbf{\Phi}
$$

$$
(\mathbf{t}^T\mathbf{\Phi})^T=(\mathbf{w}^T\mathbf{\Phi}^T\mathbf{\Phi})^T
$$

$$
\mathbf{\Phi}^T\mathbf{t}=\mathbf{\Phi}^T\mathbf{\Phi}\mathbf{w}
$$

$$
\mathbf{w}_{ML}=(\mathbf{\Phi}^T\mathbf{\Phi})^{-1}\mathbf{\Phi}^T\mathbf{t}
$$

# é€»è¾‘å›å½’



# å‰å¸ƒæ–¯åˆ†å¸ƒï¼ˆp269-p270ï¼‰

$$p(x)=\frac{1}{Z}e^{-\frac{1}{T}U(x)}$$

- èƒ½é‡å‡½æ•°ï¼š
$$U(x)=\Sigma_{c \in \mathbf{C}} V_c(\mathbf{x})$$
- é…åˆ†å‡½æ•°ï¼š
$$Z=\Sigma_{x}e^{-\frac{1}{T}U(x)}$$
- æ¸©åº¦ï¼š
$$T$$

- å®šä¹‰åœ¨å›¢cä¸Šçš„å‰å¸ƒæ–¯åŠ¿å‡½æ•°:
$$V_c(\mathbf{x})$$

ä»»æ„å•ä½ç‚¹sæ˜¯ä¸€ä¸ªå›¢ï¼›å…ƒç´ æ•°ç›®å¤§äº1çš„å­é›†
$$c \in \mathbf{C}$$
ï¼Œè‹¥Cä¸­ä»»æ„ä¸¤ä¸ªä¸åŒä½ç‚¹éƒ½ç›¸é‚»ï¼Œåˆ™Cæ˜¯ä¸€ä¸ªå›¢ã€‚æ‰€æœ‰å›¢çš„é›†åˆç”¨
$$\mathbf{C}$$
è¡¨ç¤º

## å‰å¸ƒæ–¯ä¸é©¬å°”å¯å¤«çš„ç­‰ä»·
å‚è€ƒ
[The Hammersley-Clifford
Theorem and its Impact on
Modern Statistics
Helge Langseth](https://originalstatic.aminer.cn/misc/billboard/aml/Hammersley-Clifford\%20Theorem.pdf)

**Hammersley-Cliffordâ€™s theorem**çš„ç»“è®ºä¸º

ä¸€ä¸ªæ— å‘å›¾æ¨¡å‹çš„æ¦‚ç‡å¯ä»¥è¡¨ç¤ºä¸ºå®šä¹‰åœ¨å›¾ä¸Šæ‰€æœ‰æœ€å¤§å›¢ä¸Šçš„åŠ¿å‡½æ•°çš„ä¹˜ç§¯

The following are equivalent (given the positivity
condition):

- Local Markov property : 
$$ p(x_i | x \backslash \{x_i\}) = p(xi | N (xi)) $$

- Factorization property : The probability factorizes according
to the cliques of the graph

- Global Markov property : 
$$p(x_A | x_B , x_S ) = p(x_A | x_S )$$
whenever xA and xB are separated by xS in G

å…·ä½“è¯æ˜å¯ä»¥çœ‹åŸæ–‡æˆ–è€…[yizt-Hammersley-Cliffordå®šç†è¯æ˜](https://www.jianshu.com/p/dd27249b8c4a)

# éšé©¬å°”å¯å¤«æ¨¡å‹ä¸‰ä¸ªåŸºæœ¬é—®é¢˜

HMMç”±äº”ä¸ªè¦ç´ å†³å®šï¼šçŠ¶æ€ç©ºé—´Sï¼Œè¾“å‡ºé›†Yï¼ŒçŠ¶æ€è½¬ç§»çŸ©é˜µPï¼Œè¾“å‡ºæ¦‚ç‡çŸ©é˜µQï¼Œåˆå§‹çŠ¶æ€åˆ†å¸ƒÏ€

- æ¨¡å‹ç»“æ„ï¼šSã€Y
- æ¨¡å‹å‚æ•°ï¼š
$$\lambda = (P,Q,\pi)$$

## é—®é¢˜ä¸€ è¯„ä¼°é—®é¢˜ï¼šè®¡ç®—ç»™å®šæ¨¡å‹ç”ŸæˆæŸè§‚æµ‹è¾“å‡ºåºåˆ—çš„æ¦‚ç‡
ç»™å®šæ¨¡å‹å‚æ•°Î»å’Œè§‚æµ‹åºåˆ—yï¼Œè®¡ç®—ç»™å®šæ¨¡å‹ç”ŸæˆæŸè§‚æµ‹è¾“å‡ºåºåˆ—çš„æ¦‚ç‡ï¼Œé€šè¿‡å¯¹æ¯”å„ä¸ªæ¨¡å‹è¾“å‡ºæ¦‚ç‡ï¼Œæ¦‚ç‡æœ€å¤§çš„æ¨¡å‹ä¸ºè¯†åˆ«ç»“æœã€‚

è§£å†³ï¼šåŠ æ³•åŸç†

## é—®é¢˜äºŒ è§£ç é—®é¢˜
ç»™å®šæ¨¡å‹Î»å’Œè§‚æµ‹åºåˆ—yï¼Œå¯»æ‰¾æœ€æœ‰å¯èƒ½äº§ç”Ÿè§‚å¯Ÿåºåˆ—çš„çŠ¶æ€åºåˆ—sï¼Œå¯ä»¥æœ€å¥½åœ°è§£é‡Šè§‚æµ‹åºåˆ—ã€‚
## é—®é¢˜ä¸‰ å­¦ä¹ é—®é¢˜
ç»™å®šå¤šä¸ªè§‚æµ‹åºåˆ—yï¼Œæ‰¾å‡ºæœ€ä¼˜æ¨¡å‹å‚æ•°é›†Î»ã€‚


# é‡è¦é‡‡æ ·ï¼ˆp519-523ï¼‰

åŸºäºå‡è®¾ï¼šæ— æ³•ç›´æ¥ä»p(z)ä¸­é‡‡æ ·ï¼Œä½†å¯¹äºä»»ä¸€ç»™å®šçš„zå€¼ï¼Œå¯ä»¥å¾ˆå®¹æ˜“åœ°è®¡ç®—p(z)çš„å€¼ã€‚ä»¿ç…§æ‹’ç»é‡‡æ ·çš„æ€è·¯ï¼Œå¯ä»¥åˆ©ç”¨æè®®åˆ†å¸ƒ;ä¸æ‹’ç»é‡‡æ ·ä¸åŒçš„æ˜¯ï¼šæè®®åˆ†å¸ƒè¦ä½¿ç”¨**æœ€ä¼˜**çš„é‡‡æ ·å‡½æ•°ï¼Œ**ä¸ç”¨ä¸€å®šå…¨éƒ¨è¦†ç›–**åŸåˆ†å¸ƒå‡½æ•°ï¼›å¹¶ä¸”æ‰€æœ‰ç”Ÿæˆçš„æ ·æœ¬éƒ½ä¼šè¢«ä¿ç•™ã€‚

å¦‚æœç›´æ¥ä»p(z)ä¸­é‡‡æ ·ï¼Œå¦‚æœæœ‰æœä»p(z)çš„Lä¸ªç‹¬ç«‹æ ·æœ¬ï¼Œå°±å¯ä»¥ä»

$$
E(f)=\int f(\mathbf{z})p(\mathbf{z})d\mathbf{z}
$$

è¿‡æ¸¡åˆ°

$$
f\approx\frac{1}{L}  \sum_{l=1}^L f(\mathbf{z}^{(l)})
$$

å› æ­¤æˆ‘ä»¬å¯ä»¥ä»q(z)ä¸­é‡‡æ ·ï¼Œä¹˜ä¸€ä¸ªç³»æ•°ï¼Œå°†q(z)å½“ä½œp(z)çš„ä½œç”¨ï¼Œä»

$$
E(f)=\int f(\mathbf{z})\frac{p(\mathbf{z})}{q(\mathbf{z})} q(\mathbf{z})d\mathbf{z}
$$

è¿‡æ¸¡åˆ°

$$
\hat f\approx\frac{1}{L}  \sum_{l=1}^L \frac{p(\mathbf{z}^{(l)})}{q(\mathbf{z}^{(l)})}f(\mathbf{z}^{(l)})
$$

ä¹˜ä¸Šçš„è¿™ä¸ªç³»æ•°æ˜¯**é‡è¦æ€§æƒé‡**

$$
r_l=\frac{p(\mathbf{z}^{(l)})}{q(\mathbf{z}^{(l)})}
$$

æ­¤å¤–é‡‡æ ·å¾—åˆ°çš„éœ€è¦å½’ä¸€åŒ–ï¼Œå› æ­¤å¼•å…¥

$$
p(\mathbf{z})= \frac{1}{Z_p} \tilde p(\mathbf{z})
$$

$$
q(\mathbf{z})= \frac{1}{Z_q} \tilde q(\mathbf{z})
$$

è¿™æ ·æœŸæœ›å°±å˜æˆäº†

$$
E(f)=\int f(\mathbf{z})p(\mathbf{z})d\mathbf{z}
=\int f(\mathbf{z})\frac{p(\mathbf{z})}{q(\mathbf{z})} q(\mathbf{z})d\mathbf{z}
=\frac{Z_q}{Z_p} \int f(\mathbf{z})\frac{\tilde p(\mathbf{z})}{ \tilde q(\mathbf{z})}  q(\mathbf{z})d\mathbf{z}
$$

$$
\approx\frac{Z_q}{Z_p} \frac{1}{L}  \sum_{l=1}^L \frac{\tilde p(\mathbf{z}^{(l)})}{\tilde q(\mathbf{z}^{(l)})}f(\mathbf{z}^{(l)})
=\frac{Z_q}{Z_p} \frac{1}{L}  \sum_{l=1}^L \tilde r_l f(\mathbf{z}^{(l)})
=\frac{Z_q}{\int \tilde p(\mathbf{z})d\mathbf{z}} \frac{1}{L}  \sum_{l=1}^L \tilde r_l f(\mathbf{z}^{(l)})
$$

$$
=\frac{Z_q}{\int \frac {\tilde p(\mathbf{z})}{\frac{\tilde q(\mathbf{z})}{Z_q}} q(\mathbf{z}) d\mathbf{z}} \frac{1}{L}  \sum_{l=1}^L \tilde r_l f(\mathbf{z}^{(l)})
=\frac{\frac{1}{L}  \sum_{l=1}^L \tilde r_l f(\mathbf{z}^{(l)})}{\int \frac {\tilde p(\mathbf{z})}{\tilde q(\mathbf{z})} q(\mathbf{z}) d\mathbf{z}} 
=\frac{\frac{1}{L}  \sum_{l=1}^L \tilde r_l f(\mathbf{z}^{(l)})}{\frac{1}{L}  \sum_{l=1}^L \tilde r_l } 
$$

$$
=\frac{  \sum_{l=1}^L \tilde r_l f(\mathbf{z}^{(l)})}{  \sum_{l=1}^L \tilde r_l } 
=\sum_{l=1}^L\frac{   \tilde r_l }{  \sum_{m=1}^M \tilde r_m } f(\mathbf{z}^{(l)})
=\sum_{l=1}^L\frac{   \frac{\tilde p(\mathbf{z}^{(l)})}{\tilde q(\mathbf{z}^{(l)})} }{  \sum_{m=1}^M \frac{\tilde p(\mathbf{z}^{(m)})}{\tilde q(\mathbf{z}^{(m)})} } f(\mathbf{z}^{(l)})
=\sum_{l=1}^Lw_l f(\mathbf{z}^{(l)})
$$

# Metropolis-Hastingæ–¹æ³•ï¼ˆp525-526ï¼‰

åœ¨åŸºæœ¬Metropolisç®—æ³•ä¸­ï¼Œå‡è®¾æè®®åˆ†å¸ƒï¼ˆè½¬ç§»æ ¸å‡½æ•°ï¼‰æ˜¯**å¯¹ç§°**çš„ï¼Œä½†Metropolis-Hastingsç®—æ³•æ— æ­¤é™åˆ¶

**ç®—æ³•æµç¨‹**ï¼š

åˆå§‹åŒ–ï¼šæœ€å¤§è¿­ä»£æ¬¡æ•°Tï¼Œéœ€è¦æ ·æœ¬æ•°ç›®nï¼Œåˆå§‹åŒ–æ ·æœ¬ $$\mathbf{z^{(0)}} \sim q(\mathbf{z})$$

å¾ªç¯è¿­ä»£ï¼š

- ä»æè®®åˆ†å¸ƒqä¸­é‡‡æ ·å¾—åˆ°æ ·æœ¬å€¼ $$ \mathbf{z}^* $$

- ä»å‡åŒ€åˆ†å¸ƒä¸­é‡‡æ ·$$u \sim (0,1)$$

- å¦‚æœ$$A(\mathbf{z}^* , \mathbf{z}^{(\tau)})= min{\left( 1,\frac{\tilde p(\mathbf{z}^*) q(\mathbf{z}^{(\tau)}|\mathbf{z}^* )}{\tilde p(\mathbf{z}^{(\tau)}) q(\mathbf{z}^*| \mathbf{z}^{(\tau)})}\right) }>u$$ï¼Œ
åˆ™æ¥å—$$\mathbf{z}^*$$ï¼Œå³$$\mathbf{z}^{(\tau+1)}=\mathbf{z}^*$$ï¼›
å¦åˆ™$$\mathbf{z}^*$$è¢«èˆå¼ƒï¼Œä¸”$$\mathbf{z}^{(\tau+1)}=\mathbf{z}^{(\tau)}$$ï¼›

- å¦‚æœæœªè¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œå¾ªç¯ä¸Šè¿°è¿‡ç¨‹ï¼›å¦åˆ™åœæ­¢

è¾“å‡ºï¼šæ ¹æ®éœ€è¦æˆªå–å°¾éƒ¨nä¸ªæ ·æœ¬

å¦‚æœåªæ˜¯åŸºæœ¬Metropolisç®—æ³•ï¼Œç”±äºqæ˜¯å¯¹ç§°çš„ï¼Œæ‰€ä»¥$$A(\mathbf{z}^* , \mathbf{z}^{(\tau)})=min{ \left( 1,\frac{\tilde p(\mathbf{z}^*) }{\tilde p(\mathbf{z}^{(\tau)}) }\right) }$$

æ­¤å¤„å‚è€ƒäº†[Persist_Zhang](https://blog.csdn.net/weixin_39753819/article/details/136620415)çš„åšå®¢å†…å®¹
```python
import numpy as np
import matplotlib.pyplot as plt
import scipy.stats as stats

# æˆ‘ä»¬æƒ³è¦é‡‡æ ·çš„ç›®æ ‡åˆ†å¸ƒpï¼Œä»¥åŒå³°é«˜æ–¯æ··åˆåˆ†å¸ƒä¸ºä¾‹
def p(x):
    return 0.3 * stats.norm.pdf(x, loc=2, scale=0.5) + 0.8 * stats.norm.pdf(x, loc=6, scale=0.5)

# è½¬ç§»æ ¸å‡½æ•°,å³æè®®åˆ†å¸ƒqï¼Œä»¥éå¯¹ç§°çš„å¯¹ç§°éšæœºæ¸¸èµ°ä¸ºä¾‹
def q(x):
    if np.random.rand() < 0.5:
        return stats.norm.rvs(loc=x + 0.5, scale=2)  # å‘å³ç§»åŠ¨
    else:
        return stats.norm.rvs(loc=x - 0.5, scale=3)  # å‘å·¦ç§»åŠ¨

# Metropolis-Hastingsç®—æ³•
def metropolis_hastings(target_dist, trans_kernel, n_samples):
    samples = []
    # åˆå§‹çŠ¶æ€
    current_state = 0 
    for _ in range(n_samples):
        # ä»æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒqä¸­é‡‡æ ·å¾—åˆ°æ–°çš„æ ·æœ¬å€¼
        candidate_state = trans_kernel(current_state)  
        # è®¡ç®—æ¥å—æ¦‚ç‡
        acceptance_prob = min(1, target_dist(candidate_state) / target_dist(current_state))  
        # ä»å‡åŒ€åˆ†å¸ƒä¸­é‡‡æ ·ï¼Œå†³å®šæ˜¯å¦æ¥å—å€™é€‰çŠ¶æ€
        if np.random.rand() < acceptance_prob:
            # è‹¥æ¥å—ï¼Œåˆ™è½¬ç§»é‡‡æ ·ç‚¹
            current_state = candidate_state
        samples.append(current_state)
    return samples

# é‡‡æ ·è¿‡ç¨‹
samples = metropolis_hastings(p, q, n_samples=5000)

# ç»˜åˆ¶æ ·æœ¬åˆ†å¸ƒå›¾åƒ
plt.figure(figsize=(10, 6))
x = np.linspace(0, 10, 1000)
plt.plot(x, p(x), label='p Distribution', color='blue')
plt.hist(samples, bins=50, density=True, label='M-H Distribution', color='skyblue', alpha=0.7)
plt.xlabel('x')
plt.ylabel('Density')
plt.legend()
plt.show()

```

<img src="https://github.com/Sihan0229/Sihan0229.github.io/blob/master/assets/Metropolis-Hastings.png?raw=true" width="100%">